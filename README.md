# 使用GBDT做文本分类

## 1. 数据预处理：

### 1.1 读取数据

获取数据集，对数据集进行分析。由于给定的数据集里面包含很多的文件数据，考虑对其先进行读取操作。读取的每个文件都是一个文本文档，将每个文本文档文件都当做一个str存放到数组中。在存放数组时，先读取整个文本内容，判断是否存在于已有的数组中。若存在，则将其从数组中移除。反之，加入到数组中。对于标签的处理是先设置一个字典，其中key值为标签名，value值为标签id。标签id为0到19的数值。设定一个标签id的数组，在每次存放文件的时候，将标签id也存放到标签数组中。

### 1.2 数据处理

对于获取到的数组文件，对其进行数据清洗，词干提取，去除停用词操作。其中数据清洗操作主要是对文本中的大小写进行处理，全部转换为小写，去除里面的数字，标点符号等，然后将多个空格合并为一个空格。清洗之后就进行词干提取，采用nltk中的PorterStemmer。之后对数据进行分词和去除停用词操作。其中停用词直接采用nltk中的停用词表。

### 1.3 划分数据

采用sklearn中的train_test_split方法进行随机划分训练集和测试集。其中测试集所占的比重是0.3。

## 2. 数据向量化：

经过数据处理之后的数据需要将其进行向量化处理。采用的是sklearn中的CountVectorizer和TfidfTransformer的结合。

### 2.1 CountVectorizer

获取数据的词频信息，提取文本特征。对每个训练文本它只考虑每种词汇在该训练文本中出现的次数。

### 2.2 TfidfTransformer

TF-IDF是一种常用于文本处理的方式。将获取到的词频信息转化为词频频率。

## 3. 训练模型

GBDT是一个迭代的决策树算法。直接调用sklearn里面的GBDT库，设置迭代次数进行训练即可。

也利用朴素贝叶斯模型和SVM模型进行训练，得到的结果进行相应的比较。发现GBDT的效果要优于这两个模型。